{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 목적: PDF 파일들 => vectorstore (faise_index)\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/22 5-2-1-1(1지도서).pdf loaded\n",
      "2/22 5-2-1-1(2지도서).pdf loaded\n",
      "3/22 5-2-1-1(3지도서).pdf loaded\n",
      "4/22 5-2-1-1(4지도서).pdf loaded\n",
      "5/22 5-2-1-1(5지도서).pdf loaded\n",
      "6/22 5-2-1-1(6지도서).pdf loaded\n",
      "7/22 5-2-1-1(7지도서).pdf loaded\n",
      "8/22 5-2-1-2(10지도서).pdf loaded\n",
      "9/22 5-2-1-2(11지도서).pdf loaded\n",
      "10/22 5-2-1-2(12지도서).pdf loaded\n",
      "11/22 5-2-1-2(13지도서).pdf loaded\n",
      "12/22 5-2-1-2(14지도서).pdf loaded\n",
      "13/22 5-2-1-2(8지도서).pdf loaded\n",
      "14/22 5-2-1-2(9지도서).pdf loaded\n",
      "15/22 5-2-1-3(15지도서).pdf loaded\n",
      "16/22 5-2-1-3(16지도서).pdf loaded\n",
      "17/22 5-2-1-3(17지도서).pdf loaded\n",
      "18/22 5-2-1-3(18지도서).pdf loaded\n",
      "19/22 5-2-1-3(19-20지도서).pdf loaded\n",
      "20/22 5-2-1-3(21지도서).pdf loaded\n",
      "21/22 5-2-1-3(22지도서).pdf loaded\n",
      "22/22 5-2-1-3(23-24지도서).pdf loaded\n",
      "Total 22 documents loaded\n"
     ]
    }
   ],
   "source": [
    "## 1) 문서 업로드: pdf 읽고 doc_list 저장\n",
    "\n",
    "data_dir = \"/Users/hyungseok/Desktop/src/history_chatbot/data\"\n",
    "\n",
    "doc_list = []\n",
    "pdf_list = sorted([i for i in os.listdir(data_dir) if i.endswith(\".pdf\")])\n",
    "\n",
    "for idx, pdf_name in enumerate(pdf_list):\n",
    "    loader = PyPDFLoader(os.path.join(data_dir, pdf_name))\n",
    "    documents = loader.load_and_split()\n",
    "    doc_list.extend(documents)\n",
    "    print(f\"{idx+1}/{len(pdf_list)} {pdf_name} loaded\")\n",
    "    \n",
    "print(f\"Total {idx+1} documents loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) 문서 분할\n",
    "import tiktoken\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=900,\n",
    "        chunk_overlap=100,\n",
    "        length_function=tiktoken_len\n",
    "    )\n",
    "\n",
    "chunks = text_splitter.split_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) 문서 임베딩\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"jhgan/ko-sroberta-multitask\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")  \n",
    "\n",
    "vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "vectordb.save_local(\"faiss_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
